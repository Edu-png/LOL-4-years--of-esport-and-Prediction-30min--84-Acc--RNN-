# -*- coding: utf-8 -*-
"""League_Project_Final

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W_G_6rdcbnORiIIcy7bUgTdF_F_Gempb

██╗░░░░░███████╗░█████╗░░██████╗░██╗░░░██╗███████╗  ██████╗░░█████╗░████████╗░█████╗░
██║░░░░░██╔════╝██╔══██╗██╔════╝░██║░░░██║██╔════╝  ██╔══██╗██╔══██╗╚══██╔══╝██╔══██╗
██║░░░░░█████╗░░███████║██║░░██╗░██║░░░██║█████╗░░  ██║░░██║███████║░░░██║░░░███████║
██║░░░░░██╔══╝░░██╔══██║██║░░╚██╗██║░░░██║██╔══╝░░  ██║░░██║██╔══██║░░░██║░░░██╔══██║
███████╗███████╗██║░░██║╚██████╔╝╚██████╔╝███████╗  ██████╔╝██║░░██║░░░██║░░░██║░░██║
╚══════╝╚══════╝╚═╝░░╚═╝░╚═════╝░░╚═════╝░╚══════╝  ╚═════╝░╚═╝░░╚═╝░░░╚═╝░░░╚═╝░░╚═╝

██████╗░██████╗░░█████╗░░░░░░██╗███████╗░█████╗░████████╗
██╔══██╗██╔══██╗██╔══██╗░░░░░██║██╔════╝██╔══██╗╚══██╔══╝
██████╔╝██████╔╝██║░░██║░░░░░██║█████╗░░██║░░╚═╝░░░██║░░░
██╔═══╝░██╔══██╗██║░░██║██╗░░██║██╔══╝░░██║░░██╗░░░██║░░░
██║░░░░░██║░░██║╚█████╔╝╚█████╔╝███████╗╚█████╔╝░░░██║░░░
╚═╝░░░░░╚═╝░░╚═╝░╚════╝░░╚════╝░╚══════╝░╚════╝░░░░╚═╝░░░

League of Legends competitive matches between 2015-2017. The matches include the NALCS, EULCS, LCK, LMS, and CBLoL leagues as well as the World Championship and Mid-Season Invitational tournaments.

dados - https://www.kaggle.com/code/jonathanbouchet/lol-games-4-years-of-esport/input

Script desenvolvido por Eduardo Silva Coqueiro (https://github.com/Edu-png)

# Primeiro vamos dar uma olhada em algumas estatísticas gerais:

- Analisar o data set como um todo e plotar as variações de tempo, vitória e derrota e comparativos entre ligas e anos.
"""

# 1. Impotando as bibliotecas as quais irei usar:

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import json

# 2. Importando data set diretamente do Kaggle para o colab:

dt = pd.read_csv('/content/LeagueofLegends.csv')

# 3 Exploração inicial dos dados & Analises descritivas:

#3.1. Olhando os dados:
dt.head(10)

#3.3. Coletando informações sobre os dados:
dt.info()

#3.3. Observando valores estatísticos relevantes:
dt.describe()

#3.4. Vendo o número de linhas e colunas: (3760 linhas, 29 colunas)
dt.shape

#3.5. Verrificando se há valores nulos:
dt.isnull().sum()

# Não há nenhum valor nulo no nosso dt!

# 4. Pré-processamento dos dados:

# 4.1. Como vimos que não há valores nulos, não se faz necessário o processo de substituilos ou excluilos. Poderiamos:

# Remover linhas com valores ausentes
#dt_limpo = df.dropna()

# Ou preencher valores ausentes com a média
#dt['coluna'].fillna(dt['coluna'].mean(), inplace=True)

# 4.2. Ao observar os tipos de colunas, também vimos que não é necessário realizar nenhum tipo de mudança. Mas poderiamos usar:

#dt['coluna_name'] = pd.to_datetime(dt['data']) #por exemplo.

# 4.3. Outra coisa que poderiamos fazer é categorizar os dados numéricos em categóricas ou vice versa, mas no momento não iremos fazer isso.

#3.1. Olhando os dados novamente antes de plotar os gráficos:

dt.head(10)

# 5. Vamos fazer a visualização gráfica de algumas colunas importantes:

# Primeiro, vamos fazer algumas analises em função dos anos:

# 5.1. [Year]:

# Para ano primeiro temos que fazer o somatório dos valores por ano.
contagem_anos = dt['Year'].value_counts()

# Ordenar os valores por ano (índice)
contagem_anos = contagem_anos.sort_index()

# Criar o histograma com a cor azul e barras largas
plt.bar(contagem_anos.index.astype(str), contagem_anos.values, color='skyblue', width=0.5) # Coloco o astype(str) para ter apenas os valores pontuais.

# Adicionar rótulos e título
plt.xlabel('Ano', fontsize=12)
plt.ylabel('Total de partidas', fontsize=12)
plt.title('Distribuição de Partidas por Ano', fontsize=14)

# Ajustar o tamanho da figura
plt.figure(figsize=(8, 6))

# Mostrando o gráfico
plt.show()

# 5.2. [Season]:

season_count = dt['Season'].value_counts()
season_count

# Ajustar o tamanho da figura
plt.figure(figsize=(8, 6))

# Criar o histograma com a cor vermelha e barras largas
plt.bar(season_count.index.astype(str), season_count.values, color='red', width=0.5)

# Adicionar rótulos e título
plt.xlabel('Season', fontsize=12)
plt.ylabel('Total de partidas', fontsize=12)
plt.title('Distribuição de Partidas por Season', fontsize=14)

# Rotacionar os rótulos do eixo x em 45 graus
plt.xticks(rotation=45)

# Exibir o gráfico
plt.show()

# 5.3. [gamelength] pelo ano:

plt3 = plt.hist(dt['gamelength'])
plt.xlabel('Duração dos jogos (Min)')
plt.ylabel(' ')
plt.title('Duração média dos jogos 2014 - 2016')
plt.show()

# 5.3.1 Ainda em [gamelength], eu gostaria de ver a duração dos jogos por ano:

# Obter os anos únicos
anos_unicos = np.sort(dt['Year'].unique()) # Usando o np.sort para aparecerem em ordem
num_anos = len(anos_unicos)

# Calcular o número de linhas e colunas necessárias
num_linhas = int(np.ceil(num_anos / 2))  # Assumindo 2 colunas para um layout equilibrado

# Definir o tamanho da figura para acomodar múltiplos gráficos
plt.figure(figsize=(15, 5 * num_linhas))  # Ajustar a altura da figura conforme necessário

# Loop para criar um histograma para cada ano
for i, ano in enumerate(anos_unicos):
    plt.subplot(num_linhas, 2, i+1)  # Subplots organizados dinamicamente
    plt.hist(dt[dt['Year'] == ano]['gamelength'], bins=20, color='skyblue', edgecolor='black')
    plt.xlabel('Duração dos jogos (Min)')
    plt.ylabel('Frequência')
    plt.title(f'Duração dos jogos em {ano}')

# Ajustar layout para que os gráficos não se sobreponham
plt.tight_layout()

# Mostrar os gráficos
plt.show()

# 5.3.2 Vamos ainda plotar um gráfico com a duração média dos jogos por ano:

# Agrupar os dados por ano e calcular a duração média dos jogos
media_duracao_anos = dt.groupby('Year')['gamelength'].mean()

# Criar o gráfico de barras
plt.figure(figsize=(10, 6))
plt.bar(media_duracao_anos.index.astype(str), media_duracao_anos.values, color='skyblue', width=0.5)

# Adicionar rótulos e título
plt.xlabel('Ano', fontsize=12)
plt.ylabel('Duração média dos jogos (Min)', fontsize=12)
plt.title('Duração Média dos Jogos por Ano', fontsize=14)

# Mostrar o gráfico
plt.show()

# Selecionar apenas as colunas necessárias
data = dt[['League', 'Season', 'gamelength']]

# Configurar o estilo do seaborn
sns.set(style="whitegrid")

# Criar a figura e os eixos
g = sns.FacetGrid(data, col="League", col_wrap=4, height=4, sharex=True, sharey=True)

# Adicionar gráfico de densidade
g.map_dataframe(sns.kdeplot, x="gamelength", fill=True, common_norm=False, alpha=.5)

# Definir a paleta de cores
palette = sns.color_palette("Set2", len(data['League'].unique()))

# Aplicar as cores a cada faceta
for ax, color in zip(g.axes.flat, palette):
    for patch in ax.collections:
        patch.set_facecolor(color)
        patch.set_alpha(0.5)

# Adicionar título e rótulos aos eixos
g.set_axis_labels("minutos", "")
g.set_titles("{col_name}")

# Ajustar a posição da legenda
g.add_legend(title='Liga', loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=7, frameon=False)

# Mostrar o gráfico
plt.show()

# 5.3.3 Vamos trabalhar um pouco com as taxas de vitória em função dos anos em em função dos lados:

# Calcular as vitórias e derrotas por ano para cada equipe já que não temos uma coluna apenas "resultados"
vitorias_azul = dt.groupby('Year')['bResult'].sum()
derrotas_azul = dt.groupby('Year')['rResult'].count() - vitorias_azul

vitorias_vermelho = dt.groupby('Year')['rResult'].sum()
derrotas_vermelho = dt.groupby('Year')['bResult'].count() - vitorias_vermelho

# Calcular as taxas de vitória e derrota
taxas_azul = pd.DataFrame({
    'Vitória': vitorias_azul,
    'Derrota': derrotas_azul
})
taxas_vermelho = pd.DataFrame({
    'Vitória': vitorias_vermelho,
    'Derrota': derrotas_vermelho
})

# Criar gráfico de barras empilhadas para as equipes azul e vermelho
fig, ax = plt.subplots(1, 2, figsize=(15, 6), sharey=True)

taxas_azul.plot(kind='bar', stacked=True, ax=ax[0], color=['skyblue', 'lightcoral'], edgecolor='black')
ax[0].set_title('Taxas de Vitória e Derrota - Time Azul')
ax[0].set_xlabel('Ano')
ax[0].set_ylabel('Quantidade')

taxas_vermelho.plot(kind='bar', stacked=True, ax=ax[1], color=['skyblue', 'lightcoral'], edgecolor='black')
ax[1].set_title('Taxas de Vitória e Derrota - Time Vermelho')
ax[1].set_xlabel('Ano')

plt.suptitle('Taxas de Vitória e Derrota por Ano')
plt.show()

"""# Conclusões em função da analise de tempo:

Em função do tempo já é possível inferir algumas conclusões sobre o nosso data set:

- Vemos que o ano de 2016 é o que mais concentra partidas de todos os 4 anos juntos;
- Spring Season e Summer Season são as seasons com maior números de jogos;
- O tempo de duração média dos jogos foi algo entre 35 - 45 minutos;
- Ao pegarmos a média geral dos anos, é possível ver que não há uma diferença muito grande dentre os 4, com a duração média entre 35 e 40 minutos.
- A taxa de vitória também é parelha entre os anos, o que é importante para que possamos ver que não há nenhuma vantagem tática para um dos lados nas partidas.

"""

# 6.0 Analise por ligas:

# O data set compila todas as ligas nas quais os jogos foram realizados, sendo elas:

"""
CBLOL : Circuito Brasileiro de League of Legends is a tournament that features professional Brazillian teams
Europe : League of Legends Championship Series (EU LCS) 1st (professional) Europe Berlin
LCK : League of Legends Champions Korea (LCK) 1st (professional) South Korea Seoul
LMS : League of Legends Masters Series (LMS) 1st (professional)[LNL] TW/HK/MO Taipei
Mid-Season_Invitational : is a tournament being hosted by Riot Games between the Spring and Summer splits of the current League season
North_America : League of Legends Championship Series (NA LCS) 1st (professional) North America Los Angeles
Season_World_Championship: League of Legends World Championship is the annual professional League of Legends world championship tournament hosted by Riot Games and is the culmination of each season
Season(time during the year) : International, Regional, Spring_Playoffs, Spring_Season, Summer_Playoffs, Summer_Season, Winter_Playoffs Winter_Season
"""

# 6.1 Analise de número de jogos por liga por ano:

# Agrupar por ano e liga e contar o número de jogos
jogos_por_liga_ano = dt.groupby(['Year', 'League']).size().unstack(fill_value=0)

# Criar o gráfico de barras empilhadas
jogos_por_liga_ano.plot(kind='bar', stacked=True, figsize=(12, 8), colormap='viridis')

# Adicionar rótulos e título
plt.xlabel('Ano', fontsize=12)
plt.ylabel('Número de Jogos', fontsize=12)
plt.title('Número de Jogos por Liga por Ano', fontsize=14)
plt.legend(title='Liga')

# Mostrar o gráfico
plt.show()

# 6.2 Vamos criar também um gráfico com o número total de jogos por liga:

# Agrupar por liga e contar o número total de jogos
jogos_por_liga = dt['League'].value_counts()

# Criar o gráfico de barras
plt.figure(figsize=(12, 8))
cores = ['skyblue', 'orange', 'green', 'red']
jogos_por_liga.plot(kind='bar', color=cores, edgecolor='black')

# Adicionar rótulos e título
plt.xlabel('Liga', fontsize=12)
plt.ylabel('Número de Jogos', fontsize=12)
plt.title('Número Total de Jogos por Liga', fontsize=14)

# Mostrar o gráfico
plt.show()

# 6.3 Vamos analisar número de jogos por Season, breakdown per League and Year:

# Agrupar os dados por League, Season e Year, contando o número de jogos
grouped_data = dt.groupby(['League', 'Season', 'Year']).size().reset_index(name='number')

# Visualizar os dados agrupados
print(grouped_data.head(20))  # Agrupados por Liga, Season e Ano!

# Configurar o estilo do seaborn
sns.set(style="whitegrid")

# Criar a figura e os eixos
g = sns.FacetGrid(grouped_data, col="Season", col_wrap=3, height=4, sharex=True, sharey=True)
g = g.map_dataframe(sns.scatterplot, x="Year", y="League", size="number", hue="number", sizes=(20, 200), palette="viridis", legend=False)

# Ajustar a posição da legenda para a última subplot
handles, labels = g.axes.flat[-1].get_legend_handles_labels()
legend1 = g.axes.flat[-1].legend(handles, labels, loc='upper right', bbox_to_anchor=(1.25, 1), borderaxespad=0., title='Number')

# Criar um handle para a legenda de tamanho
for ax in g.axes.flat:
    sizes = [20, 50, 100, 150, 200]
    labels = ["20", "50", "100", "150", "200"]
    handles = [plt.scatter([], [], s=size, edgecolor='none') for size in sizes]

# Ajustar a posição da legenda de tamanho das bolhas na última subplot
legend2 = g.axes.flat[-1].legend(loc='upper right', bbox_to_anchor=(1.25, 0.7), borderaxespad=0., title='Size')

# Ajustar a posição da legenda de tamanho das bolhas
ax.legend(handles, labels, loc='upper right', bbox_to_anchor=(1.25, 1), borderaxespad=0., title='Number')

# Adicionar título e rótulos aos eixos
g.set_titles("{col_name}")
g.set_axis_labels("Ano", "Liga")

# Mostrar o gráfico
plt.show()

"""# Agora que já vimos estatísticas gerais, vamos dar uma olhada em estatísticas por partida:

Explicação rápida do procedimento :

- Selecionar um jogo e transpô-lo de forma a ter os minutos como linhas
- Fundir este conjunto de dados com o conjunto global para obter o resultado da equipa azul e da equipa vermelha
- Adicionar novas colunas para os minutos
- Adicionar um fator para o resultado do jogo
- plotar: se a diferença em ouro for positiva, significa que a equipa azul tem mais ouro do que a equipa vermelha, por isso adicionei um código de cores
"""

# Vamos pegar como exemplo o jogo 1#

# 7.0 Analisando esse jogo em específico: Diferença de ouro entre os times

# Para fazer essas analises individuais, vamos trabalhar com outros arquivos que também estão disponíveis no Dataset: https://www.kaggle.com/code/jonathanbouchet/lol-games-4-years-of-esport/input

# Carregar os arquivos CSV:

gold = pd.read_csv('/content/gold.csv', sep=',')
deaths = pd.read_csv('/content/deathValues.csv', sep=',')
objects = pd.read_csv('/content/objValues.csv', sep=',')
bans = pd.read_csv('/content/bans.csv', sep=',')

gold.head()

deaths.head()

objects.head()

bans.head()

# 7.1 Diferença de ouro entre os times:

# Golddiif = gold_blue - gold_red

# Selecionar um jogo específico
game_id0 = 1 # Peguei o ID game 0 que corresponde ao 1 do data set usado no R.

# Obtendo o MatchHistory específico para o game_id
game_index0 = dt['MatchHistory'].iloc[game_id0]

# Filtrando os dados de mortes para o jogo específico e mesclando com os dados globais
resD0 = deaths[deaths['MatchHistory'] == game_index0].merge(
    dt[['MatchHistory', 'League', 'Season', 'Year', 'blueTeamTag', 'bResult', 'redTeamTag', 'rResult', 'gamelength']],
    on='MatchHistory',
    how='left'
)

# Limitar os dados até o minuto 45
game_data = gold.iloc[game_id0, 3:48]

# Transpor os dados de ouro para ter minutos como linhas
game1 = pd.DataFrame(game_data.values, columns=['gold_diff'])
game1['time'] = range(1, len(game1) + 1)
game1['MatchHistory'] = dt['MatchHistory'].iloc[0]

# Mesclar com o DataFrame dt para obter informações sobre o resultado das equipes azul e vermelha
res = pd.merge(game1, dt[['MatchHistory', 'League', 'Season', 'Year', 'blueTeamTag', 'bResult', 'redTeamTag', 'rResult', 'gamelength']], on='MatchHistory', how='left')

# Adicionar uma coluna para indicar o resultado do jogo
res['blueTeam'] = ['BLUE:W ; RED:L' if result == 1 else 'BLUE:L ; RED:W' for result in res['bResult']]

# Definir cores para os times
colors = {'BLUE:W ; RED:L': {'BLUE': '#3B9AB2', 'RED': '#FF0000'}, 'BLUE:L ; RED:W': {'BLUE': '#FF0000', 'RED': '#3B9AB2'}}

# Plotar o gráfico
plt.figure(figsize=(10, 6))

# Definir paleta de cores personalizada
palette = ['#FF0000' if value < 0 else '#3B9AB2' for value in res['gold_diff']]

sns.barplot(data=res, x='time', y='gold_diff', dodge=False, palette=palette)
plt.xlabel('Minutos')
plt.ylabel('Diferença de ouro entre a equipe Azul e Vermelha')

# Criar o título do gráfico
title = resD0['blueTeamTag'].iloc[0] + ' (lado azul)' + " vs " + resD0['redTeamTag'].iloc[0] + ' (lado vermelho)'

# Definir marcadores para aparecerem a cada 10 minutos
plt.xticks(range(0-1, len(game1) + 1, 10))

# Adicionar o título ao gráfico
plt.title(title)

plt.show()

# 7.2 Números de kills pelo tempo jogado:

# Agora vamos trabalhar na proporção comparativa de mortes entre equipes, usando o seguinte critério:

# +1 para uma morte da equipe azul para a equipe vermelha
# -1 para uma morte da equipe vermelha para a equipe azul

# Vamos comparar esse conjunto de dados ao conjunto global:

# Importando algumas adições para o gráfico:
import plotly.express as px
import plotly.graph_objs as go
from plotly.subplots import make_subplots

# Definindo o game_id
game_id = 1000 # Analisando o jogo 1000

# Obtendo o MatchHistory específico para o game_id
game_index = dt['MatchHistory'].iloc[game_id]

# Filtrando os dados de mortes para o jogo específico e mesclando com os dados globais
resD = deaths[deaths['MatchHistory'] == game_index].merge(
    dt[['MatchHistory', 'League', 'Season', 'Year', 'blueTeamTag', 'bResult', 'redTeamTag', 'rResult', 'gamelength']],
    on='MatchHistory',
    how='left'
)

# Aplicando o critério de contagem de kills
resD['kill_direction'] = resD.apply(lambda row: 1 if row['TeamColor'] == 'Blue' else -1, axis=1)

# Criando o gráfico de barras com Plotly Express
fig = px.bar(
    resD,
    x='Time',  # Tempo em minutos
    y='kill_direction',  # Direção das kills (1 ou -1)
    color='TeamColor',  # Cor das barras baseada na equipe
    color_discrete_map={'Blue': '#18598B', 'Red': '#A32020'},  # Mapeamento de cores
    title=resD['blueTeamTag'].iloc[0] + ' (lado azul) '+" vs " + resD['redTeamTag'].iloc[0] + ' (lado vermelho)',  # Título do gráfico
)

# Ajustando a opacidade das barras
fig.update_traces(opacity=1, marker_line_width=0)

# Ajustando o layout do gráfico
fig.update_layout(
    xaxis_title="Minutos",
    yaxis_title="Ocorrência de abates",
    showlegend=False,  # Não mostrar legenda neste exemplo
)

# Mostrando o gráfico
fig.show()

# 7.3 Agora vamos analisar os dados referentes a abates de monstros neutros:

# Essencialmente vamos criar um gráfico desses já criados por variável e depois juntar todos:

# Inicialmente vamos filtrar os dados por equipe:

# Definindo o ID do jogo
game_id1 = 2 # Ajuste conforme necessário para o seu caso, vendo o jogo que quiser

# Filtrando os dados para a equipe Red
tempR = objects[(objects['MatchHistory'] == dt['MatchHistory'][game_id1])
               & (objects['ObjType'].str.startswith('r'))].drop(['MatchHistory', 'ObjType'], axis=1).T
tempR['Team'] = 'red'
tempR.columns = ['Towers', 'Inhibs', 'Dragons', 'Barons', 'Heralds', 'Team']

# Filtrando os dados para a equipe Blue
tempB = objects[(objects['MatchHistory'] == dt['MatchHistory'][game_id1])
               & (objects['ObjType'].str.startswith('b'))].drop(['MatchHistory', 'ObjType'], axis=1).T
tempB['Team'] = 'blue'
tempB.columns = ['Towers', 'Inhibs', 'Dragons', 'Barons', 'Heralds', 'Team']

# Concatenando os DataFrames
resObjects = pd.concat([tempB, tempR])

# Obtendo o MatchHistory específico para o game_id
game_index = dt['MatchHistory'].iloc[game_id1]

# Filtrando os dados de mortes para o jogo específico e mesclando com os dados globais
resD2 = deaths[deaths['MatchHistory'] == game_index].merge(
    dt[['MatchHistory', 'League', 'Season', 'Year', 'blueTeamTag', 'bResult', 'redTeamTag', 'rResult', 'gamelength']],
    on='MatchHistory',
    how='left'
)

# Mostrando o DataFrame resultante
print(resObjects)

# Essencialmente vamos criar 5 gráficos iguais ao anterior e agrupar eles:
# Aqui eu optei por fazer isso com outras bibliotecas pela facilidade maior de agrupar os 5!
from matplotlib.gridspec import GridSpec


# Transformar o dataframe para formato longo
resObjects_long = resObjects.melt(id_vars='Team', var_name='ObjType', value_name='Time').dropna()

# Adicionar uma nova coluna para indicar a direção das barras
resObjects_long['Value'] = resObjects_long.apply(lambda row: 1 if row['Team'] == 'blue' else -1, axis=1)

# Função para criar cada subplot
def create_subplot(ax, objType, ylabel):
    subset = resObjects_long[resObjects_long['ObjType'] == objType]
    if not subset.empty:
        for team in ['blue', 'red']:
            team_subset = subset[subset['Team'] == team]
            for _, row in team_subset.iterrows():
                ax.bar(row['Time'], row['Value'], width=0.2, color='#3B9AB2' if team == 'blue' else '#F21A00', edgecolor='black', linewidth=0.8)
                ax.bar(row['Time'], row['Value'] * 0.5, width=0.2, color='#3B9AB2' if team == 'blue' else '#F21A00', edgecolor='black', linewidth=0.8)
        ax.set_ylabel(ylabel, fontsize=10)
        ax.set_xlabel('minutos', fontsize=10)  # Rótulo do eixo x
        ax.set_xlim(0, 40)  # Ajuste do limite do eixo x para 0 a 40 minutos
        ax.set_xticks(range(0, 41, 5))  # Definir os ticks do eixo x de 0 a 40 com intervalo de 5 minutos
        ax.set_ylim(-1, 1)  # Ajuste do limite do eixo y
        ax.axhline(0, color='black',linewidth=0.2)
        if objType == 'Heralds':  # Adiciona a legenda apenas no último subplot
            ax.legend(handles=[
                plt.Line2D([0], [0], color='#3B9AB2', lw=4, label='Blue Team'),
                plt.Line2D([0], [0], color='#F21A00', lw=4, label='Red Team')
            ], loc='upper right')
        else:
            ax.legend().set_visible(False)
    else:
        # Se o subset estiver vazio, configurar apenas os eixos sem plotar nada
        ax.set_ylabel(ylabel, fontsize=10)
        ax.set_xlabel('minutos', fontsize=10)
        ax.set_xlim(0, 40)
        ax.set_xticks(range(0, 41, 5))
        ax.set_ylim(-1, 1)
        ax.axhline(0, color='black',linewidth=0.5)
        ax.legend().set_visible(False)

    # Ajustando a espessura das linhas
    for spine in ax.spines.values():
      spine.set_linewidth(2)  # Define a espessura das bordas dos gráficos
    ax.tick_params(width=2)  # Define a espessura das linhas dos ticks

    # Ajustando a cor das bordas e ticks
    ax.spines['top'].set_color('black')
    ax.spines['bottom'].set_color('black')
    ax.spines['left'].set_color('black')
    ax.spines['right'].set_color('black')
    ax.xaxis.label.set_color('black')
    ax.yaxis.label.set_color('black')
    ax.tick_params(axis='x', colors='black')
    ax.tick_params(axis='y', colors='black')

# Configurações gerais do gráfico
plt.figure(figsize=(12, 10))
gs = GridSpec(6, 1, height_ratios=[1, 1, 1, 1, 1, 1])

# Criando subplots para cada tipo de objeto
ax1 = plt.subplot(gs[0])
create_subplot(ax1, 'Towers', 'Towers')

ax2 = plt.subplot(gs[1])
create_subplot(ax2, 'Inhibs', 'Inhibs')

ax3 = plt.subplot(gs[2])
create_subplot(ax3, 'Dragons', 'Dragons')

ax4 = plt.subplot(gs[3])
create_subplot(ax4, 'Barons', 'Barons')

ax5 = plt.subplot(gs[4])
create_subplot(ax5, 'Heralds', 'Heralds')

# Adicionando título acima dos gráficos
plt.suptitle(resD2['blueTeamTag'].iloc[0] + " (lado azul)" " VS " + resD2['redTeamTag'].iloc[0] + " (lado vermelho)", fontsize=16, y=0.93)

plt.tight_layout(rect=[0, 0, 1, 0.95])  # Ajuste para garantir que o título não se sobreponha aos gráficos
plt.show()

resObjects_long.head(100)

# 7.4 Agora vamos juntar todas essas informações em um único plot:

# Essencialmente vamos unir o gráfico anterior com o de kills e o de diferença de ouro:

# Primeiro vamos repetir os gráficos já feitos:

# Selecionar um jogo específico
game_idf = 2122  # Peguei o ID game

# Filtrando os dados para a equipe Red
tempR = objects[(objects['MatchHistory'] == dt['MatchHistory'][game_idf])
               & (objects['ObjType'].str.startswith('r'))].drop(['MatchHistory', 'ObjType'], axis=1).T
tempR['Team'] = 'red'
tempR.columns = ['Towers', 'Inhibs', 'Dragons', 'Barons', 'Heralds', 'Team']

# Filtrando os dados para a equipe Blue
tempB = objects[(objects['MatchHistory'] == dt['MatchHistory'][game_idf])
               & (objects['ObjType'].str.startswith('b'))].drop(['MatchHistory', 'ObjType'], axis=1).T
tempB['Team'] = 'blue'
tempB.columns = ['Towers', 'Inhibs', 'Dragons', 'Barons', 'Heralds', 'Team']

# Concatenando os DataFrames
resObjects = pd.concat([tempB, tempR])

# Obtendo o MatchHistory específico para o game_id
game_indexf = dt['MatchHistory'].iloc[game_idf]

# Filtrando os dados de mortes para o jogo específico e mesclando com os dados globais
resDf = deaths[deaths['MatchHistory'] == game_indexf].merge(
    dt[['MatchHistory', 'League', 'Season', 'Year', 'blueTeamTag', 'bResult', 'redTeamTag', 'rResult', 'gamelength']],
    on='MatchHistory',
    how='left'
)

# Mostrando o DataFrame resultante
print(resObjects)

# Transformar o dataframe para formato longo
resObjects_long = resObjects.melt(id_vars='Team', var_name='ObjType', value_name='Time').dropna()

# Adicionar uma nova coluna para indicar a direção das barras
resObjects_long['Value'] = resObjects_long.apply(lambda row: 1 if row['Team'] == 'blue' else -1, axis=1)

# Função para criar cada subplot
def create_subplot(ax, objType, ylabel):
    subset = resObjects_long[resObjects_long['ObjType'] == objType]
    if not subset.empty:
        for team in ['blue', 'red']:
            team_subset = subset[subset['Team'] == team]
            for _, row in team_subset.iterrows():
                ax.bar(row['Time'], row['Value'], width=0.2, color='#3B9AB2' if team == 'blue' else '#F21A00', edgecolor='black', linewidth=0.8)
                ax.bar(row['Time'], row['Value'] * 0.5, width=0.2, color='#3B9AB2' if team == 'blue' else '#F21A00', edgecolor='black', linewidth=0.8)
        ax.set_ylabel(ylabel, fontsize=10)
        ax.set_xlabel('minutos', fontsize=10)  # Rótulo do eixo x
        ax.set_xlim(0, 40)  # Ajuste do limite do eixo x para 0 a 40 minutos
        ax.set_xticks(range(0, 41, 5))  # Definir os ticks do eixo x de 0 a 40 com intervalo de 5 minutos
        ax.set_ylim(-1, 1)  # Ajuste do limite do eixo y
        ax.axhline(0, color='black', linewidth=0.2)
        if objType == 'Heralds':  # Adiciona a legenda apenas no último subplot
            ax.legend(handles=[
                plt.Line2D([0], [0], color='#3B9AB2', lw=4, label='Blue Team'),
                plt.Line2D([0], [0], color='#F21A00', lw=4, label='Red Team')
            ], loc='upper right')
        else:
            ax.legend().set_visible(False)
    else:
        # Se o subset estiver vazio, configurar apenas os eixos sem plotar nada
        ax.set_ylabel(ylabel, fontsize=10)
        ax.set_xlabel('minutos', fontsize=10)
        ax.set_xlim(0, 40)
        ax.set_xticks(range(0, 41, 5))
        ax.set_ylim(-1, 1)
        ax.axhline(0, color='black', linewidth=0.5)
        ax.legend().set_visible(False)

    # Ajustando a espessura das linhas
    for spine in ax.spines.values():
        spine.set_linewidth(2)  # Define a espessura das bordas dos gráficos
    ax.tick_params(width=2)  # Define a espessura das linhas dos ticks

    # Ajustando a cor das bordas e ticks
    ax.spines['top'].set_color('black')
    ax.spines['bottom'].set_color('black')
    ax.spines['left'].set_color('black')
    ax.spines['right'].set_color('black')
    ax.xaxis.label.set_color('black')
    ax.yaxis.label.set_color('black')
    ax.tick_params(axis='x', colors='black')
    ax.tick_params(axis='y', colors='black')

# Função para criar o subplot da diferença de ouro
def create_gold_diff_subplot(ax, resDf, title):
    palette = ['#F21A00' if value < 0 else '#3B9AB2' for value in resDf['gold_diff']]
    sns.barplot(data=resDf, x='time', y='gold_diff', dodge=False, palette=palette, ax=ax)
    ax.set_xlabel('minutos', fontsize=10)
    ax.set_ylabel('Diferença de ouro', fontsize=10)
    ax.set_title(title, fontsize=12)
    ax.set_xticks(range(-1, 41, 5))
    ax.axhline(0, color='black', linewidth=0.5)
    ax.set_xticks(range(-1, 41, 5))
    ax.set_ylim(-3000, 3000)  # Ajuste do limite do eixo y

    # Ajustando a espessura das linhas
    for spine in ax.spines.values():
        spine.set_linewidth(2)  # Define a espessura das bordas dos gráficos
    ax.tick_params(width=2)  # Define a espessura das linhas dos ticks

    # Ajustando a cor das bordas e ticks
    ax.spines['top'].set_color('black')
    ax.spines['bottom'].set_color('black')
    ax.spines['left'].set_color('black')
    ax.spines['right'].set_color('black')
    ax.xaxis.label.set_color('black')
    ax.yaxis.label.set_color('black')
    ax.tick_params(axis='x', colors='black')
    ax.tick_params(axis='y', colors='black')

# Função para criar o subplot de kills
def create_kills_subplot(ax, resDf):
    resDf['kill_direction'] = resDf.apply(lambda row: 1 if row['TeamColor'] == 'Blue' else -1, axis=1)
    sns.barplot(data=resDf, x='Time', y='kill_direction', hue='TeamColor', dodge=False, ax=ax, palette={'Blue': '#3B9AB2', 'Red': '#A32020'})
    ax.set_xlabel('minutos', fontsize=10)
    ax.set_ylabel('Abates', fontsize=10)
    ax.axhline(0, color='black', linewidth=0.5)
    ax.legend().set_visible(False)  # Remove a legenda do gráfico
    ax.set_xlim(0, 40)  # Define o limite do eixo x de 0 a 40 minutos
    ax.set_xticks(range(0, 41, 5))  # Define os ticks do eixo x de 0 a 40 com intervalo de 5 minutos
    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: int(x)))  # Força os valores dos ticks a serem inteiros

    # Ajustando a espessura das linhas
    for spine in ax.spines.values():
        spine.set_linewidth(2)  # Define a espessura das bordas dos gráficos
    ax.tick_params(width=2)  # Define a espessura das linhas dos ticks

    # Ajustando a cor das bordas e ticks
    ax.spines['top'].set_color('black')
    ax.spines['bottom'].set_color('black')
    ax.spines['left'].set_color('black')
    ax.spines['right'].set_color('black')
    ax.xaxis.label.set_color('black')
    ax.yaxis.label.set_color('black')
    ax.tick_params(axis='x', colors='black')
    ax.tick_params(axis='y', colors='black')

# Configurações gerais do gráfico
plt.figure(figsize=(12, 16))
gs = GridSpec(8, 1, height_ratios=[1, 1, 1, 1, 1, 2, 1, 1])

# Criando subplots para cada tipo de objeto
ax1 = plt.subplot(gs[0])
create_subplot(ax1, 'Towers', 'Towers')

ax2 = plt.subplot(gs[1])
create_subplot(ax2, 'Inhibs', 'Inhibs')

ax3 = plt.subplot(gs[2])
create_subplot(ax3, 'Dragons', 'Dragons')

ax4 = plt.subplot(gs[3])
create_subplot(ax4, 'Barons', 'Barons')

ax5 = plt.subplot(gs[4])
create_subplot(ax5, 'Heralds', 'Heralds')

# Adicionando o gráfico de diferença de ouro

# Limitar os dados até o minuto 45
game_data = gold.iloc[game_id0, 3:48]

# Transpor os dados de ouro para ter minutos como linhas
game = pd.DataFrame(game_data.values, columns=['gold_diff'])
game['time'] = range(1, len(game) + 1)
game['MatchHistory'] = dt['MatchHistory'].iloc[game_idf]

# Mesclar com o DataFrame dt para obter informações sobre o resultado das equipes azul e vermelha
res = pd.merge(game, dt[['MatchHistory', 'League', 'Season', 'Year', 'blueTeamTag', 'bResult', 'redTeamTag', 'rResult', 'gamelength']], on='MatchHistory', how='left')

# Adicionar uma coluna para indicar o resultado do jogo
res['blueTeam'] = ['BLUE:W ; RED:L' if result == 1 else 'BLUE:L ; RED:W' for result in res['bResult']]

# Criar o título do gráfico de diferença de ouro
title = resDf['blueTeamTag'].iloc[0] + ' (blue side)' + " vs " + resDf['redTeamTag'].iloc[0] + ' (red side)'

# Adicionar o subplot de diferença de ouro
ax6 = plt.subplot(gs[5])
create_gold_diff_subplot(ax6, res, ' ')

# Obtendo o MatchHistory específico para o game_id
game_indexf = dt['MatchHistory'].iloc[game_idf]

ax7 = plt.subplot(gs[6])
create_kills_subplot(ax7, resDf)

# Adicionando título acima dos gráficos
plt.suptitle(resDf['blueTeamTag'].iloc[0] + " (lado azul)" " VS " + resDf['redTeamTag'].iloc[0] + " (lado vermelho)", fontsize=16, y=0.93)

plt.tight_layout(rect=[0, 0, 1, 0.95])  # Ajuste para garantir que o título não se sobreponha aos gráficos
plt.show()

"""# Agora vamos trabalhar com outras variáveis (sobretudo relacionadas a gold), primeiro veremos Ouro vs Tempo de jogo, a lógica vai ser a seguinte:

- Desvincular Vencedor/Perdedor e Obter Dados Globais:
 - Desvincularemos os dados dos vencedores e perdedores e obtenha os dados globais.

- Mesclar o Resultado com o Conjunto de Dados de Valores de Ouro:
  - Mesclaremos o resultado obtido com o conjunto de dados de valores de ouro usando a coluna MatchHistory e selecione a característica apropriada.

- Calcular a Média, Máximo e Mínimo ao Longo do Tempo:
  - Calcularemos a média, o valor máximo e o valor mínimo dos valores de ouro ao longo do tempo.

- Plotar com Barras de Erro:
  - Faremos um gráfico com barras de erro para representar as médias, máximos e mínimos calculados.

- Dividir Tudo por Ano:
  - Faremos a divisão dos dados e plots por ano.
"""

# Vamos dar uma olhada na estrutura dos datasets que vamos trabalhar
gold.head(100)

# Vamos dar uma olhada na estrutura dos datasets que vamos trabalhar
dt.head(100)

#8.0 Vamos iniciar com Gold Values vs Time Played

# Primeiro vamos montar o nosso data set por anos separando vencedores de perdedores

def get_gold(year, dt, gold):
    # Selecionar blue como vencedores (bW - Blue winners)
    bW = pd.merge(
        dt[(dt['bResult'] == 1) & (dt['Year'] == year)][['MatchHistory', 'gamelength', 'Season', 'Year', 'blueTeamTag', 'redTeamTag']],
        gold[gold['Type'] == 'goldblue'],
        left_on='MatchHistory',
        right_on='Address'
    )

    # Selecionar red como vencedores (rW - Red winners)
    rW = pd.merge(
        dt[(dt['rResult'] == 1) & (dt['Year'] == year)][['MatchHistory', 'gamelength', 'Season', 'Year', 'blueTeamTag', 'redTeamTag']],
        gold[gold['Type'] == 'goldred'],
        left_on='MatchHistory',
        right_on='Address'
    )

    # Combinar os datasets
    all_wins = pd.concat([bW, rW])
    games_w = all_wins.iloc[:, 8:].T  # Ajustando para selecionar todas as colunas de min_1 em diante

    # Calcular mean, max e min para todos os jogos (WG - Winners gold!)
    meanWG = games_w.mean(axis=1)
    minWG = games_w.min(axis=1)
    maxWG = games_w.max(axis=1)

    # Selecionar blue como perdedores (bL - Blue Losers)
    bL = pd.merge(
        dt[(dt['bResult'] == 0) & (dt['Year'] == year)][['MatchHistory', 'gamelength', 'Season', 'Year', 'blueTeamTag', 'redTeamTag']],
        gold[gold['Type'] == 'goldblue'],
        left_on='MatchHistory',
        right_on='Address'
    )

    # Selecionar red como perdedores (rL - Red Losers)
    rL = pd.merge(
        dt[(dt['rResult'] == 0) & (dt['Year'] == year)][['MatchHistory', 'gamelength', 'Season', 'Year', 'blueTeamTag', 'redTeamTag']],
        gold[gold['Type'] == 'goldred'],
        left_on='MatchHistory',
        right_on='Address'
    )

    # Combinar os datasets
    all_loses = pd.concat([bL, rL])
    games_l = all_loses.iloc[:, 8:].T  # Ajustando para selecionar todas as colunas de min_1 em diante

    # Calcular mean, max e min para todos os jogos (LG - Losers gold!)
    meanLG = games_l.mean(axis=1)
    minLG = games_l.min(axis=1)
    maxLG = games_l.max(axis=1)

    # Combinar todos os resultados
    res = pd.DataFrame({
        'meanWG': meanWG,
        'minWG': minWG,
        'maxWG': maxWG,
        'meanLG': meanLG,
        'minLG': minLG,
        'maxLG': maxLG,
        'time': np.arange(1, len(meanWG) + 1),
        'year': year
    })

    return res

# Carregar dados
global_data = dt
gold_data = gold

# Verificar colunas
print("Global Data Columns:", global_data.columns)
print("Gold Data Columns:", gold_data.columns)

# Obter dados para cada ano
gold_2014 = get_gold(2014, global_data, gold_data)
gold_2015 = get_gold(2015, global_data, gold_data)
gold_2016 = get_gold(2016, global_data, gold_data)
gold_2017 = get_gold(2017, global_data, gold_data)

# Combinar todos os resultados
res = pd.concat([gold_2014, gold_2015, gold_2016, gold_2017])
res.head(100)
# Em res temos os valores de média, min e máx de WG (Winners gold) e os valores de média, min e máx de LG (losers gold)!

# 8.1 Agora vamos plotar nossos gráficos:

# 8.2 Média de Ouro por ano:

# Plotar os resultados
palette = ["#78B7C5", "#EBCC2A", "#F8AFA8", "#F21A00"]

fig, axes = plt.subplots(1, 2, figsize=(18, 8), sharey=True)

# Combinar todos os resultados e garantir índices únicos
res = pd.concat([gold_2014, gold_2015, gold_2016, gold_2017]).reset_index(drop=True)

# Plot para os vencedores
sns.scatterplot(ax=axes[0], data=res, x='time', y='meanWG', hue='year', palette=palette)
axes[0].set_title('Ouro médio dos ganhadores')
axes[0].set_xlabel('Minutos')
axes[0].set_ylabel('Gold médio')
axes[0].legend(title='Ano', loc='upper left')

# Plot para os perdedores
sns.scatterplot(ax=axes[1], data=res, x='time', y='meanLG', hue='year', palette=palette)
axes[1].set_title('Ouro médio dos perdedores')
axes[1].set_xlabel('Minutos')
axes[1].legend(title='Ano', loc='upper left')

plt.suptitle('Ouro médio vs. Tempo jogado por ano', fontsize=16)
plt.show()


# Vemos que o valor médio do ouro é semelhante para 2016 e 2017, e para 2014 e 2015!

# 8.3 Ouro médio vs. tempo jogado por ano, dividido por vitória/derrota:

# Preparar os dados para o plot
res_win = res[['time', 'meanWG', 'year']].rename(columns={'meanWG': 'mean_gold'})
res_win['result'] = 'win'

res_loss = res[['time', 'meanLG', 'year']].rename(columns={'meanLG': 'mean_gold'})
res_loss['result'] = 'loss'

res_combined = pd.concat([res_win, res_loss]).reset_index(drop=True)

# Plotar os resultados
g = sns.FacetGrid(res_combined, col="year", hue="result", palette={"win": "#3B9AB2", "loss": "#F21A00"}, col_wrap=4, height=5)
g.map(sns.scatterplot, 'time', 'mean_gold').add_legend()
g.set_axis_labels("Minutos", "Gold médio adquirido")
g.set_titles("{col_name}")

plt.subplots_adjust(top=0.9)
g.fig.suptitle('Ouro médio vs. tempo jogado por ano, divisão por vitória/derrota', fontsize=12)
plt.subplots_adjust(top=0.85)
plt.show()

"""Agora, vemos um comportamento (comum a todos os anos) em que a equipe vencedora recebeu mais ouro (aproximadamente) no meio do jogo do que as equipes perdedoras. Esse pode ser um recurso a ser levado em conta ao prever se uma equipe vencerá ou perderá em um modelo preditivo por exemplo!"""

# 8.4 Agora vamos plotar esse mesmo gráfico com algumas medidas de erro:

# Função para criar um plot individual
def plot_with_error_bars(ax, data, x, y, ymin, ymax, color, label, title):
    ax.errorbar(data[x], data[y], yerr=[data[y] - data[ymin], data[ymax] - data[y]], fmt='o', ecolor='black', alpha=0.25)
    sns.lineplot(ax=ax, data=data, x=x, y=y, color=color, label=label)
    ax.set_title(title)
    ax.legend().set_visible(False)

# Criar a figura e os eixos
fig, axes = plt.subplots(2, 4, figsize=(20, 10), sharex=True, sharey=True)

# Plotar os gráficos para cada ano
years = [2014, 2015, 2016, 2017]
for i, year in enumerate(years):
    plot_with_error_bars(axes[0, i], res[res['year'] == year], 'time', 'meanWG', 'minWG', 'maxWG', '#3B9AB2', 'win', f'Vitórias de {year}')
    plot_with_error_bars(axes[1, i], res[res['year'] == year], 'time', 'meanLG', 'minLG', 'maxLG', '#F21A00', 'loss', f'Derrotas de {year}')

# Ajustar os rótulos dos eixos
for ax in axes[1, :]:
    ax.set_xlabel('Minutos')
for ax in axes[:, 0]:
    ax.set_ylabel('Gold médio adquirido')

plt.tight_layout()
plt.subplots_adjust(top=0.92)
fig.suptitle('Ouro médio vs. tempo jogado por ano, dividido por vitória/derrota com barras de erro', fontsize=16)
plt.show()

"""Os gráficos mostram que em todos os anos, tanto para vitórias quanto para derrotas, há um aumento consistente no ouro acumulado ao longo do tempo, com os times vencedores acumulando mais ouro do que os perdedores, uma diferença que se amplia à medida que o jogo avança. A variação no ouro acumulado, indicada pelas barras de erro, tende a aumentar ao longo do jogo devido a diferentes estratégias e eventos específicos. A consistência dessa tendência de 2014 a 2017 sugere que o controle de recursos é um fator crucial para a vitória, apesar das mudanças nas regras do jogo. Além disso, a ligeira elevação das curvas ao longo dos anos pode refletir alterações nas mecânicas do jogo, permitindo uma acumulação de ouro mais eficiente.

# Analise de bans:

No LOL as equipes se revezam banindo heróis que não querem que a outra equipe use, enquanto escolhem seus próprios heróis para a partida. Uma pessoa de cada equipe (a pessoa na primeira posição) é quem toma essas decisões. Em um jogo de nível profissional, isso se torna extremamente importante, pois você quer evitar que a outra equipe escolha heróis nos quais ela é especialista ou que neutralize os heróis que você escolheu. Normalmente são 5 bans para cada time, totalizando 10, mas a algum tempo eram apenas 3, e grande parte dos dados desse dataset consta 6 bans por jogo.
"""

# Verrificando os data sets que vamos usar:

bans.head(100)

# Verrificando os data sets que vamos usar:

dt.head(100)

# 9.0 Analise de bans:

# Por fim, para terminar as analises gráficas vamos realizar a analise de bans por partida:

# Definir cores
colfuncBlue = sns.color_palette("Blues", 4)
colfuncRed = sns.color_palette("Reds", 4)

# Substituir valores vazios por NA e calcular o número de bans
bans = bans.replace("", pd.NA)
bans['numBans'] = bans.iloc[:, 2:].notna().sum(axis=1)

# Carregar dados
global_data = dt
bans_data = bans  # Já carregado no ambiente como 'bans'

# Verificar as colunas do dataframe bans
print("Colunas de bans_data:", bans_data.columns)
print(bans_data.head())

# Definir cores
colfuncBlue = sns.color_palette("Blues", 4)
colfuncRed = sns.color_palette("Reds", 4)

# Substituir valores vazios por NA e calcular o número de bans
bans_data = bans_data.replace("", pd.NA)
bans_data['numBans'] = bans_data.iloc[:, 2:].notna().sum(axis=1)

# Agrupar dados de bans com dados globais
red_bans = pd.merge(global_data[['MatchHistory', 'League', 'Season', 'Year', 'redTeamTag', 'rResult', 'gamelength']],
                    bans_data[bans_data['Team'] == 'redBans'][['Address', 'numBans']], left_on='MatchHistory', right_on='Address')
red_bans['RES'] = red_bans['rResult'].apply(lambda x: 'LOSS' if x == 0 else 'WIN')

blue_bans = pd.merge(global_data[['MatchHistory', 'League', 'Season', 'Year', 'blueTeamTag', 'bResult', 'gamelength']],
                     bans_data[bans_data['Team'] == 'blueBans'][['Address', 'numBans']], left_on='MatchHistory', right_on='Address')
blue_bans['RES'] = blue_bans['bResult'].apply(lambda x: 'LOSS' if x == 0 else 'WIN')

# Verificar se os dados foram corretamente agrupados
print(red_bans.head())
print(blue_bans.head())

# Plotar os dados com FacetGrid para Red Team Bans
g_red = sns.FacetGrid(red_bans, col="RES", hue="Year", palette=colfuncRed, sharex=True, sharey=True, height=6, aspect=1.5)
g_red.map(sns.countplot, 'numBans', order=sorted(red_bans['numBans'].unique())).add_legend(title="Year")
g_red.set_axis_labels("Número de bans", " ")
g_red.set_titles("{col_name}")
g_red.set(yscale="log")

# Plotar os dados com FacetGrid para Blue Team Bans
g_blue = sns.FacetGrid(blue_bans, col="RES", hue="Year", palette=colfuncBlue, sharex=True, sharey=True, height=6, aspect=1.5)
g_blue.map(sns.countplot, 'numBans', order=sorted(blue_bans['numBans'].unique())).add_legend(title="Year")
g_blue.set_axis_labels("numBans", " ")
g_blue.set_titles("{col_name}")
g_blue.set(yscale="log")

plt.show()

"""Como podemos ver, o número de proibições aumentou em 2017 de 3 para 5. Ou seja, esse foi o namo em que haviamos comentado.

# Agora vamos trabalhar com Machine Learning para fazer um preditor para determinar o vencedor de partidas de League of Legends aos 30 minutos de jogo, utilizando Redes Neurais Recorrentes (RNN).


- Esse código é feito com base no trabalho de: https://www.kaggle.com/code/nailian23/lol-winner-prediction-from-30min-84-acc-rnn/notebook

- No momento estou estudando RNN, então essa parte é feita com esse intuito, mas usando o mesmo data set!

- Por estar estudando, o código tem o maior número de comentários possíveis, pois estou buscando entender cada linha de maneira crítica.
"""

# 10 Inicialmente vamos importar todas as bibliotecas necessárias:

import math
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader, random_split
from torch.autograd import Variable
from tqdm import tqdm
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore') # Suprime avisos desnecessários para manter o ambiente de trabalho limpo. Boa prática para RNN.

RANDOM_SEED = 0 # Define a semente aleatória para garantir reprodutibilidade. Mesma usada pelo autor original do cógigo
MAX_TIME_STEP = 30 # Define o passo máximo de tempo para os dados de entrada, que representa os 30 minutos de jogo. Assim como o autor do código original.

print(dt.columns)

# 10.1 O próximo passo seria carregar nosso data set e filtrar, o data set é muito parecido com o "dt" com algumas modificações. Vou chamar ele de df.

df = pd.read_csv('/content/LeagueofLegends1.csv')

# Vamos filtar para trabalhar apenas com o tempo que queremos:

df = df[df['gamelength'] >= MAX_TIME_STEP]
df.reset_index(drop = True, inplace = True)

# Calculando e imprimindo o número total de partidas restantes depois da filtragem:

matches = len(dt)
print(f'# of matches: {matches}')

# Conversão de dados: Converte a coluna golddiff de strings que representam listas para listas reais usando literal_eval. Essa conversão permite que você utilize funções e métodos do Python para manipular os dados dentro dessas listas, o que não seria possível se elas permanecessem como strings.

from ast import literal_eval
df['golddiff'] = df['golddiff'].apply(literal_eval)
df[['golddiff']].head()

# Criando uma função que cria um array que conta o número de eventos (itens) que ocorrem até cada ponto no tempo, até um limite de 30 minutos (ou passos de tempo).

def count_item(items):
    count = np.zeros(MAX_TIME_STEP, dtype=np.int8) # Itera sobre o tempo, indo de 0 a 29.
# Cria um array count de zeros, com tamanho MAX_TIME_STEP (30), para armazenar a contagem cumulativa de itens. O tipo de dado é int8 para economizar memória.
    for timestep in range(MAX_TIME_STEP):
        for item in items:
            if item[0] <= timestep + 1:
                count[timestep] += 1
    return count # Retorna o array count que agora contém a contagem cumulativa de itens até cada ponto no tempo.
# Aplicar a função aos dados de dragões
df['bDragons'] = df['bDragons'].apply(literal_eval)
df['rDragons'] = df['rDragons'].apply(literal_eval)

df['bDragons'] = df['bDragons'].apply(count_item)
df['rDragons'] = df['rDragons'].apply(count_item)
df['dragondiff'] = df['bDragons'] - df['rDragons']

# Verificar o resultado
df[['dragondiff']].tail()

# Aqui vamos transformar os dados temporais de abates de barões em uma série temporal acumulada, permitindo analisar a vantagem ou desvantagem acumulada em termos de barões abatidos ao longo do tempo na partida. Isso pode ser útil para prever o resultado da partida com base no desempenho dos times em abater barões.

df['bBarons'] = df['bBarons'].apply(literal_eval)
df['rBarons'] = df['rBarons'].apply(literal_eval)

df['bBarons'] = df['bBarons'].apply(count_item)
df['rBarons'] = df['rBarons'].apply(count_item)
df['barondiff'] = df['bBarons'] - df['rBarons']

df[['barondiff']].head()

# Mesma coisa para harolds

df['bHeralds'] = df['bHeralds'].apply(literal_eval)
df['rHeralds'] = df['rHeralds'].apply(literal_eval)

df['bHeralds'] = df['bHeralds'].apply(count_item)
df['rHeralds'] = df['rHeralds'].apply(count_item)
df['heralddiff'] = df['bHeralds'] - df['rHeralds']

df[['heralddiff']].head()

# Para torres:

df['bTowers'] = df['bTowers'].apply(literal_eval)
df['rTowers'] = df['rTowers'].apply(literal_eval)

df['bTowers'] = df['bTowers'].apply(count_item)
df['rTowers'] = df['rTowers'].apply(count_item)
df['towerdiff'] = df['bTowers'] - df['rTowers']

df[['towerdiff']].head()

# Para inibidores:

df['bInhibs'] = df['bInhibs'].apply(literal_eval)
df['rInhibs'] = df['rInhibs'].apply(literal_eval)

df['bInhibs'] = df['bInhibs'].apply(count_item)
df['rInhibs'] = df['rInhibs'].apply(count_item)
df['inhibitordiff'] = df['bInhibs'] - df['rInhibs']

df[['inhibitordiff']].head()

# Para kills:

df['bKills'] = df['bKills'].apply(literal_eval)
df['rKills'] = df['rKills'].apply(literal_eval)

df['bKills'] = df['bKills'].apply(count_item)
df['rKills'] = df['rKills'].apply(count_item)
df['killdiff'] = df['bKills'] - df['rKills']

df[['killdiff']].head()

# Criando uma lista chamada stats com todas as colunas de interesse:

stats = ['golddiff','dragondiff', 'barondiff', 'heralddiff', 'towerdiff', 'inhibitordiff', 'killdiff']
x = df[stats] # Cria um DataFrame x que contém apenas as colunas especificadas na lista stats.
y = df['bResult'] # Cria uma variável y que contém a coluna 'bResult' do DataFrame df. b é de blue, ou seja do time azul.

x.tail() # Mostra as últimas linhas do DataFrame x para verificação e inspeção visual.

# Essencialmente unimos todas as listas criadas em um único dataframe, que será usado para ensinar.

y

# Mostra as últimas linhas da variável y para verificação e inspeção visual.
# Conferindo de y possui os dados de forma correta, ou seja, 0 para derrota e 1 para vitória!

# Normalizando os dados
# Normalizar os dados significa ajustar os valores para que eles fiquem em uma escala comum, geralmente com média zero e desvio padrão um.

# Importando a biblioteca que nos permite fazer isso:
from sklearn.preprocessing import StandardScaler

# Inicializando os dicionários:
data = {}
scalers = {}
# Loop para normalizar os dados
for stat in stats:
    scalers[stat] = StandardScaler()
#Para cada estatística em stats, cria um StandardScaler e o armazena em scalers com a chave sendo o nome da estatística.
    for row in df[stat]:
        scalers[stat].partial_fit(np.asarray(row).reshape(-1, 1))
    data[stat] = [scalers[stat].transform(np.asarray(row).reshape(-1, 1)).reshape(-1) for row in df[stat]] # Normaliza os dados!

# Calcula e imprime o número de características por passo de tempo.  Neste caso, deve ser 7, que corresponde ao número de estatísticas listadas em stats.
num_features = len(data)
print(f'# of features per timestep: {num_features}')
# 7 - golddiff	dragondiff	barondiff	heralddiff	towerdiff	inhibitordiff	killdiff

# Vamos criar uma classe LOLDataset que vai herdar de dataset do PyTorch para preparar um data set próprio para o modelo de aprendizado de máquina:

class LOLDataset(Dataset):
    def __init__(self, data, stats, label):
        self.data = [] #Inicialização das variáveis.
        for t in range(MAX_TIME_STEP):
            self.data.append([[data[stat][i][t] for stat in stats] for i in range(len(label))])
        self.label = [i for i in label]

    def __getitem__(self, item): # Método para acessar os itens.
        return torch.tensor([[torch.scalar_tensor(i) for i in x[item]] for x in self.data]), torch.tensor(self.label[item])

    def __len__(self): # Método para obter o comprimento do dataset.
        return len(self.label)

# Criando um dataset a partir de LOLDATA para ver o processo (invertendo o que fiz acima para garantir)
dataset = LOLDataset(data, stats, y)

# Verifique o comprimento do dataset
print(f'Tamanho do dataset: {len(dataset)}')

"""# Estrutura da Rede Neural usando Recurrent Neural Network (RNN):

"""

# 11. RNN:

# Definição de classe:
class RNN(nn.Module): # Define uma classe chamada RNN que herda de nn.Module do PyTorch, o que significa que é uma rede neural.
    def __init__(self):
        super(RNN, self).__init__()

# Inicalização dos parâmetros:
        self.hidden_size = 256 # Define o tamanho da camada oculta da RNN como 256 neurônios.
# Definição da RNN:
        self.rnn = nn.RNN(
            nonlinearity='relu', #  Função de ativação ReLU - função usada em redes neurais que introduz não-linearidade ao modelo, permitindo que ele aprenda representações complexas.
            input_size=num_features, # Número de características de entrada por time step.
            hidden_size=self.hidden_size, # Número de neurônios na camada oculta.
            num_layers=1, # Número de camadas na RNN.
            batch_first=True # Indica que a dimensão do batch é a primeira dimensão dos dados de entrada.
        )
# Define uma camada totalmente conectada (linear) que mapeia a saída da camada oculta para uma saída de tamanho 2, representando as duas classes possíveis (vitória ou derrota).
        self.out = nn.Linear(self.hidden_size, 2)
# Método forward:
    def forward(self, x): # Define a passagem para a frente da rede neural.
        r_out, hn = self.rnn(x, torch.zeros(1, len(x), self.hidden_size)) #Passa a entrada x pela camada RNN
        out = self.out(r_out[:, -1, :]) #Inicializa o estado oculto inicial com zeros.
        return out # Inicializa o estado oculto inicial com zeros.

"""# Treinando a rede:

- O código divide o conjunto de dados em três partes para treinamento, validação e teste, e carrega esses conjuntos em lotes para treinamento usando a proporção de 6:2:2, antecipando uma possível queda de precisão.
- Usando um tamanho de lote de 32 para carregar o conjunto de dados para treinamento.



"""

# Rotulando nossos conjuntos de dados:

BATCH_SIZE = 32 # Define o tamanho do lote como 32.

dataset = LOLDataset(data, stats, df["bResult"]) # Cria um objeto do dataset personalizado com os dados e rótulos.
test_size = valid_size = int(0.2 * len(dataset)) # Define o tamanho dos conjuntos de teste e validação como 20% (0.2) do dataset total.
train_size = len(dataset) - test_size - valid_size #  Calcula o tamanho do conjunto de treinamento como o restante dos dados (60%).

trainDataset, validDataset, testDataset = random_split( # random_split: Divide o dataset nas proporções especificadas, garantindo reprodutibilidade com manual_seed(0).
    dataset = dataset,
    lengths = [train_size, valid_size, test_size],
    generator = torch.Generator().manual_seed(0)
)

trainLoader = DataLoader(trainDataset, batch_size = BATCH_SIZE, shuffle=True) # Cria carregadores de dados para os conjuntos de treinamento, validação e teste.
# shuffle=True: Embaralha os dados de treinamento para melhorar a generalização do modelo.
validLoader = DataLoader(validDataset, batch_size = BATCH_SIZE)
testLoader = DataLoader(testDataset, batch_size = BATCH_SIZE)

# Verrificando se está tudo correto:

print(f'Tamanho do dataset: {len(dataset)}')
print(f'Tamanho do conjunto de treinamento: {train_size}')
print(f'Tamanho do conjunto de validação: {valid_size}')
print(f'Tamanho do conjunto de teste: {test_size}')

# Verrificando algumas amostras do dataset:

for i in range(5):
    x, y = dataset[i]
    print(f'Amostra {i+1}:')
    print(f'  Dados: {x}')
    print(f'  Rótulo: {y}')

correct = 0 # Inicializa o contador correct para contar o número de previsões corretas.
for x, y in dataset: # Itera sobre cada amostra x (características) e rótulo y (resultado) no dataset.
    gold_diff_last = x[-1][0].item()  # Certifique-se de obter o valor correto
    blue_won = y.item() == 1

    if (gold_diff_last > 0 and blue_won) or (gold_diff_last <= 0 and not blue_won):
        correct += 1

baseline_accuracy = correct / len(dataset) * 100
print(f'Baseline Accuracy = {baseline_accuracy:.2f}%') # Cálculo de impressão da precição

# Baseline Accuracy = 83.24%, pois estamos reproduzindo a SEED usada pelo autor do código

"""A condição de verrificação:

- x[-1][0]: Acessa a última entrada da diferença de ouro (valor no tempo final).
- (x[-1][0] > 0): Verifica se a diferença de ouro é positiva.
- (y == 1): Verifica se o rótulo indica que o time azul venceu.
- XOR (^): Verifica se exatamente uma das condições é verdadeira. O resultado da expressão será True se uma e apenas uma das condições for True.
- == 0: Verifica se a previsão está correta (ambas as condições são verdadeiras ou falsas).
- correct += 1: Incrementa o contador se a previsão estiver correta.
"""

def train(dataloader, model, loss_fn, optimizer, mute = False):
# dataloader: Fornece os dados em lotes (batches).
# model: O modelo de rede neural que está sendo treinado.
# loss_fn: Função de perda (loss function) usada para calcular o erro entre as previsões e os rótulos verdadeiros.
# optimizer: Otimizador que ajusta os pesos do modelo para minimizar a função de perda.
# mute: Flag opcional para controlar a exibição de mensagens de progresso.
    size = len(dataloader.dataset) # size: Armazena o número total de amostras no dataset.
    for batch, (x, y) in enumerate(dataloader): #  Itera sobre os batches de dados fornecidos pelo dataloader. Cada batch contém um conjunto de entradas x e rótulos y.
        x, y = Variable(x), Variable(y) #  Converte x e y em variáveis PyTorch (embora Variable seja uma prática mais antiga e muitas vezes desnecessária nas versões mais recentes do PyTorch).

        predict = model(x) # Passa as entradas x pelo modelo para obter as previsões.
        loss = loss_fn(predict, y) # Calcula a perda (erro) entre as previsões predict e os rótulos verdadeiros y.

        optimizer.zero_grad() # Zera os gradientes acumulados do otimizador.
        loss.backward() # Calcula os gradientes da perda em relação aos pesos do modelo (backpropagation).
        optimizer.step() # Atualiza os pesos do modelo com base nos gradientes calculados.

        if batch % 30 == 0 and not mute: # A cada 30 batches, exibe o progresso se mute for False.
            loss, current = loss.item(), batch * len(x) # Obtém o valor numérico da perda.
            print(f"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]") #Exibe a perda atual e o progresso do treinamento no formato especificado.

def test(dataloader, model, loss_fn, validation=False):
    model.eval() # Coloca o modelo em modo de avaliação, desativando o dropout e outras camadas específicas do modo de treinamento.
    size = len(dataloader.dataset) # Calcula o número total de amostras no dataset.

    correct = 0
    test_loss = 0 # Acumula a perda total no conjunto de teste.
    with torch.no_grad(): # Desativa a computação do gradiente para economizar memória e melhorar a eficiência durante a avaliação.
        for step, (x, y) in enumerate(dataloader):
            x, y = Variable(x), Variable(y)
            predict = model(x)
            test_loss += loss_fn(predict, y).item()
            correct += (predict.argmax(1) == y).sum().item()
    # Exibe os resultados:
    print(f"{'Valid' if validation else 'Test'} Acc: {correct/size:>7f}, Avg Loss: {test_loss/size:>7f}")

    return correct / size
    # Retorna a acurácia do modelo no conjunto de dados.

# Trainando RNN - Recurrent neural network:

MUTE = False #  Define se as mensagens de progresso durante o treinamento serão exibidas (False significa que serão exibidas).
EPOCH = 100 # Define o número de épocas para o treinamento. Em aprendizado de máquina, uma época (epoch) refere-se a um ciclo completo de treinamento em que o modelo vê todas as amostras do conjunto de dados uma vez.
LR = 0.0001 # Define a taxa de aprendizado para o otimizador.

torch.manual_seed(RANDOM_SEED) # Define a semente aleatória para o PyTorch, garantindo a reprodutibilidade dos resultados.
np.random.seed(RANDOM_SEED) #  Define a semente aleatória para o NumPy, também para garantir a reprodutibilidade.

model = RNN() # Cria uma instância do modelo RNN. Uma instância é um objeto específico da classe RNN que foi criado para ser usado no treinamento e na inferência de dados.
print(model) #  Imprime a arquitetura do modelo.

optimizer = torch.optim.Adam(model.parameters(), lr = LR) # Define o otimizador Adam, que ajusta os parâmetros do modelo usando a taxa de aprendizado definida.
loss_func = nn.CrossEntropyLoss() # Define a função de perda como entropia cruzada, adequada para classificação.

best_acc = 0 # Inicializa a melhor acurácia como 0.
early_stopping = 0 # Inicializa o contador de early stopping como 0.é uma técnica utilizada no treinamento de modelos de aprendizado de máquina para prevenir o sobreajuste (overfitting). Ele monitora a performance do modelo em um conjunto de validação e interrompe o treinamento se a performance não melhorar após um certo número de épocas consecutivas.
early_stopping_threshold = 5 # Define o limite de épocas sem melhoria na acurácia antes de parar o treinamento (early stopping).

for epoch in range(1, EPOCH + 1): # Loop que percorre cada época de 1 até EPOCH (100).
    print(f"--------- Epoch #{epoch} ---------")
    train(trainLoader, model, loss_func, optimizer, mute = MUTE)
    valid_acc = test(validLoader, model, loss_func, validation = True)
    if valid_acc > best_acc :
        early_stopping = 0
        best_acc = valid_acc
        torch.save(model.state_dict(), f"./{MAX_TIME_STEP}.pt")
    else : # Se a acurácia de validação não melhorar:
        early_stopping += 1
        if early_stopping == early_stopping_threshold :
            print(f"Early stopped at epoch #{epoch} with best validation accuracy {best_acc*100:.2f}%.")
            break

"""- O modelo mostra uma acurácia de validação relativamente alta (83.54%) antes de o treinamento ser interrompido.
- A interrupção precoce ocorre porque o modelo não mostrou melhoria na acurácia de validação após 5 épocas consecutivas, indicando um possível ponto de saturação no treinamento.
"""



"""# Testando a rede:"""

# Carregar o melhor modelo RNN:
model.load_state_dict(torch.load(f"./{MAX_TIME_STEP}.pt"))

# Avaliar o conjunto de testes:
acc_RNN = test(testLoader, model, loss_func)
print(f'Model Accuracy = {acc_RNN*100:>.2f}% ')

match_stats = {}

# Definir aqui o jogo que vc deseja ver:
''' S11 EDG vs DK, match 3, DK(red) wins '''
match_stats['golddiff'] = [0,31,16,122,-71,325,170,367,463,918,1479,1181,689,813,890,1486,2779,2215,2543,2805,2887,2975,3477,3842,3361,3450,3318,3101,754,752]
match_stats['dragondiff'] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -2, -2, -2, -2, -2, -2, -3, -3, -3, -3, -3, -3, -4, -4]
match_stats['barondiff'] = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
match_stats['heralddiff'] = [0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
match_stats['towerdiff'] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2]
match_stats['inhibitordiff'] = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
match_stats['killdiff'] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, -1, -1]


''' S11 EDG vs DK, match 4, EDG(blue) wins '''
# match_stats['golddiff'] = [0,-33,147,160,-124,-627,621,979,577,759,1136,1175,-39,554,2057,1839,2071,1771,2058,2515,2297,1408,1575,1459,1521,1525,2672,2314,2717,2417,]
# match_stats['dragondiff'] = [0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,4,4,4,4]
# match_stats['barondiff'] = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
# match_stats['heralddiff'] = [0,0,0,0,0,0,0,0,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]
# match_stats['towerdiff'] = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,1,1,1,0,0,0,0,0,1,1,1,1]
# match_stats['inhibitordiff'] = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
# match_stats['killdiff'] = [0,0,0,0,0,0,1,1,1,1,1,1,-1,-1,0,0,0,0,0,0,0,-1,-1,-1,-1,-1,-1,-1,-1,-1]


''' S11 DK vs EDG, match 5, EDG(red) wins '''
# match_stats['golddiff'] = [0,-21,-108,135,125,451,233,133,-431,-810,-860,-1128,-794,-774,-797,-886,-401,-216,-321,35,-143,-55,-734,-1719,-1955,-1864,-2100,-487,-324,-3383]
# match_stats['dragondiff'] = [0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,-1,-1,-1,-1,-1,-2,-2,-2,-2,-2,-2,-3]
# match_stats['barondiff'] = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1]
# match_stats['heralddiff'] = [0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2]
# match_stats['towerdiff'] = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,-1]
# match_stats['inhibitordiff'] = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
# match_stats['killdiff'] = [0,0,0,0,0,0,0,0,-1,-1,-2,-2,-3,-3,-3,-2,-2,-2,-2,-2,-2,-2,-5,-6,-6,-6,-6,-6,-6,-10]

for stat in stats:
    match_stats[stat] = scalers[stat].transform(np.asanyarray(match_stats[stat]).reshape(-1, 1)).reshape(-1)

x = np.asarray([[ [match_stats[stat][timestep] for stat in stats] for timestep in range(MAX_TIME_STEP) ]], dtype=np.float32)

model.eval()
with torch.no_grad():
    x = torch.from_numpy(x)
    predict = model(x)
    winner = ['red', 'blue'][predict.argmax(1)]
    prob_red = math.exp(predict[0][0].item()) / (math.exp(predict[0][0].item()) + math.exp(predict[0][1].item()))
    prob_blue = math.exp(predict[0][1].item()) / (math.exp(predict[0][0].item()) + math.exp(predict[0][1].item()))
    print(f"model predicted winner: { winner }")
    print(f"red wins: {prob_red * 100 :.1f}% | blue wins: {prob_blue * 100:.1f}%")

# Fazendo a predição de um jogo para o CBLOL de 2017:

match_stats = {}

# CBLoL, 2017, Summer, Playoffs, ONE (blue) vs RED (red) - RED VENCEU!
match_stats['golddiff'] = [0, 0, -7, -145, -326, -278, -628, -1024, -944, -1464, -2391, -2649, -3759, -2830, -2846, -4056, -5578, -6214, -6776, -8455, -7899, -8180, -9839, -11167, -12855, -14310, -17220, 0, 0, 0]
match_stats['dragondiff'] = [2500, 2500, 2695, 3992, 5358, 6761, 7857, 9366, 10483, 11628, 13050, 14501, 15907, 18047, 19353, 20546, 21620, 23214, 24516, 25995, 28022, 29446, 30833, 32615, 33986, 35199, 36009, 0, 0, 0]
match_stats['barondiff'] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
match_stats['heralddiff'] = [0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
match_stats['towerdiff'] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2]
match_stats['inhibitordiff'] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
match_stats['killdiff'] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, -1, -1]

for stat in stats:
    match_stats[stat] = scalers[stat].transform(np.asanyarray(match_stats[stat]).reshape(-1, 1)).reshape(-1)

x = np.asarray([[ [match_stats[stat][timestep] for stat in stats] for timestep in range(MAX_TIME_STEP) ]], dtype=np.float32)

model.eval()
with torch.no_grad():
    x = torch.from_numpy(x)
    predict = model(x)
    winner = ['red', 'blue'][predict.argmax(1)]
    prob_red = math.exp(predict[0][0].item()) / (math.exp(predict[0][0].item()) + math.exp(predict[0][1].item()))
    prob_blue = math.exp(predict[0][1].item()) / (math.exp(predict[0][0].item()) + math.exp(predict[0][1].item()))
    print(f"model predicted winner: { winner }")
    print(f"red wins: {prob_red * 100 :.1f}% | blue wins: {prob_blue * 100:.1f}%")

# Ou seja, o time red (RED Canadis) venceu nesse caso.

# Aplicando para um resultado de jogo de hoje em dia do CBLOL para diversão

# Atenção, aqui já não é mais tão válido, o jogo muda todo ano, os players e times também, essa linha é meramente feita por curiosidade:

match_stats = {}

# CBLoL, 2024, Summer, Playoffs, PNG (blue) vs LOUD (red) - LOUD VENCEU!

match_stats = {
    'golddiff': [0, 0, 500, 1000, 1500, 2000, 3000, 4000, 4500, 5000, 6000, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, 0, 0, 0],
    'dragondiff': [0, 0, 0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 0, 0, 0],
    'barondiff': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    'heralddiff': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
    'towerdiff': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    'inhibitordiff': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    'killdiff': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
}

for stat in stats:
    match_stats[stat] = scalers[stat].transform(np.asanyarray(match_stats[stat]).reshape(-1, 1)).reshape(-1)

x = np.asarray([[ [match_stats[stat][timestep] for stat in stats] for timestep in range(MAX_TIME_STEP) ]], dtype=np.float32)

model.eval()
with torch.no_grad():
    x = torch.from_numpy(x)
    predict = model(x)
    winner = ['red', 'blue'][predict.argmax(1)]
    prob_red = math.exp(predict[0][0].item()) / (math.exp(predict[0][0].item()) + math.exp(predict[0][1].item()))
    prob_blue = math.exp(predict[0][1].item()) / (math.exp(predict[0][0].item()) + math.exp(predict[0][1].item()))
    print(f"model predicted winner: { winner }")
    print(f"red wins: {prob_red * 100 :.1f}% | blue wins: {prob_blue * 100:.1f}%")

# Ou seja, o time red (LOUD) foi marcado como vencedor nesse caso.